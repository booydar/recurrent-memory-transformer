{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datasets\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "sys.path.append(\"..\")\n",
    "from babilong_utils import TaskDataset, SentenceSampler, NoiseInjectionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### extract dataset archive\n",
    "# !unzip ../data/tasks_1-20_v1-2.zip -d ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks_1-20_v1-2  tasks_1-20_v1-2.zip\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/\n",
    "\n",
    "VerificationMode = datasets.VerificationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt\"\n",
    "test_path = \"../data/tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt\"\n",
    "\n",
    "noise_dataset = datasets.load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load task datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task \n",
    "task_dataset_train = TaskDataset(train_path)\n",
    "task_dataset_test = TaskDataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background text\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "noise_sampler_train = SentenceSampler(noise_dataset['train'], tokenizer=tokenizer)\n",
    "noise_sampler_test = SentenceSampler(noise_dataset['test'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 64               # max number of tokens in sample\n",
    "dataset_train = NoiseInjectionDataset(task_dataset=task_dataset_train,\n",
    "                                        noise_sampler=noise_sampler_train,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        sample_size=sample_size)\n",
    "\n",
    "dataset_test = NoiseInjectionDataset(task_dataset=task_dataset_test,\n",
    "                                        noise_sampler=noise_sampler_test,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        sample_size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['facts', 'question', 'answer', 'references', 'background_text', 'fact_positions', 'input_tokens', 'target_tokens'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset_train[0]\n",
    "\n",
    "\n",
    "sample.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 2 <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sample['input_tokens']), len(sample['target_tokens']), type(sample['background_text'][0])) \n",
    "sum(len(l) for l in sample['background_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts: Mary moved to the bathroom. John went to the hallway.\n",
      "Question: Where is Mary? \n",
      "Answer: bathroom\n",
      "References: Mary moved to the bathroom.\n",
      "\n",
      "Background text:  The player progresses through a series of linear missions, gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked.\n",
      "Fact positions:  [0 1]\n",
      "Combined input:  Mary moved to the bathroom.The player progresses through a series of linear missions, gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked.John went to the hallway.Where is Mary? \n",
      "Target: bathroom\n"
     ]
    }
   ],
   "source": [
    "facts = sample['facts']\n",
    "question = sample['question']\n",
    "answer = tokenizer.decode(sample['target_tokens'])\n",
    "\n",
    "background_text = tokenizer.batch_decode(sample['background_text'])\n",
    "\n",
    "input_tokens = tokenizer.decode(sample['input_tokens'])\n",
    "\n",
    "print(f\"Facts: {' '.join(facts)}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"References: {' '.join(sample['references'])}\")\n",
    "print()\n",
    "print('Background text: ', ' '.join(background_text))\n",
    "print('Fact positions: ', sample['fact_positions'])\n",
    "print('Combined input: ', input_tokens)\n",
    "\n",
    "print(f\"Target: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "gen_token = tokenizer.encode('GEN')[0]\n",
    "eos_token = tokenizer.eos_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    targets = [torch.tensor(b['target_tokens']) for b in batch]\n",
    "    input_ids = [torch.tensor(b['input_tokens'] + [gen_token] + b['target_tokens'] + [eos_token]) for b in batch]\n",
    "    gen_inputs = [torch.tensor(b['input_tokens'] + [gen_token]) for b in batch]\n",
    "\n",
    "    attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "    labels_mask = [torch.zeros_like(b, dtype=bool) for b in input_ids]\n",
    "    for m, t in zip(labels_mask, targets):\n",
    "        m[-len(t) - 2:] = True\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    gen_inputs = pad_sequence(gen_inputs, padding_value=id_pad_value, batch_first=True)\n",
    "    # labels = pad_sequence(input_ids, padding_value=-100, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {}\n",
    "    collated['input_ids'] = collated['labels'] = input_ids\n",
    "    collated['input_ids_generate'] = gen_inputs\n",
    "    collated['labels_mask'] = labels_mask\n",
    "    collated['attention_mask'] = attention_mask.bool()\n",
    "    collated['attention_mask_generate'] = (gen_inputs != id_pad_value).bool()\n",
    "\n",
    "    collated['target_text'] = [b['answer'] for b in batch]\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'labels', 'input_ids_generate', 'labels_mask', 'attention_mask', 'attention_mask_generate', 'target_text'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [dataset_train[i] for i in range(2)]\n",
    "collated = collate_fn(batch)\n",
    "collated.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample #0\n",
      "Model INPUT at each step: ['GEN' 'bath' 'room']\n",
      "Model LABEL at each step: ['bath' 'room' '<|endoftext|>']\n",
      "\n",
      "Sample #1\n",
      "Model INPUT at each step: ['GEN' 'hall' 'way' '<|endoftext|>']\n",
      "Model LABEL at each step: ['hall' 'way' '<|endoftext|>' '<|endoftext|>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def visualize_masked_prediction(collated):\n",
    "    for i, (input_ids, labels_mask) in enumerate(zip(collated['input_ids'], collated['labels_mask'])):\n",
    "        print(f\"Sample #{i}\")\n",
    "        \n",
    "        input_t = label_t = np.asarray( tokenizer.batch_decode(input_ids) )\n",
    "        \n",
    "        shift_labels = label_t[1:]\n",
    "        shift_inputs = input_t[:-1]\n",
    "        shift_mask = labels_mask[:-1]\n",
    "        #print(labels_mask)\n",
    "        print(\"Model INPUT at each step:\", shift_inputs[shift_mask])\n",
    "        print(\"Model LABEL at each step:\", shift_labels[shift_mask])\n",
    "        print()\n",
    "        #for i in range(len(decoded_inputs)):\n",
    "        #    print(\"masked input:\", dec_inputs[i])\n",
    "\n",
    "\n",
    "visualize_masked_prediction(collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GENbathroom<|endoftext|>',\n",
       " 'GENhallway<|endoftext|>',\n",
       " 'GENhallway<|endoftext|>',\n",
       " 'GENoffice<|endoftext|>',\n",
       " 'GENbathroom<|endoftext|>',\n",
       " 'GENbathroom<|endoftext|>',\n",
       " 'GENbathroom<|endoftext|>',\n",
       " 'GENbathroom<|endoftext|>',\n",
       " 'GENoffice<|endoftext|>',\n",
       " 'GENhallway<|endoftext|>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels are marked with labels_mask\n",
    "tokenizer.batch_decode([c[m] for c, m in zip(collated['input_ids'], collated['labels_mask'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Troops are divided into five classes : Scouts, Shocktroopers, Engineers, Lancers and Armored Soldier.Troopers can switch classes by changing their assigned weapon.Changing class does not greatly affect the stats gained while in a previous class.With victory in battle, experience points are awarded to the squad, which are distributed into five different attributes shared by the entire squad, a feature differing from early games\\'method of distributing to different unit types. = = Plot = = The game takes place during the Second Europan War.Gallian Army Squad 422, also known as \" The Nameless \", are a penal military unit composed of criminals, foreign deserters, and military offenders whose real names are erased from the records and thereon officially referred to by numbers.Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do, they are nevertheless up to the task, exemplified by their motto, Altaha Abilia, meaning \" Always Ready. \"The three main characters are No.7 Kurt Irving, an army officer falsely accused of treason who wishes to redeem himself ; Ace No.1 Imca, a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and No.13 Riela Marcellis, a seemingly jinxed young woman who is unknowingly a descendant of the Valkyria.Together with their fellow squad members, these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven, consisting of mostly Darcsen soldiers.Mary moved to the bathroom. As the Nameless officially do not exist, the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose face in the war.While at times this works to their advantage, such as a successful incursion into Imperial territory, other orders cause certain members of the 422nd great distress.One such member, Gusurg, becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven, attached to the ideal of Darcsen independence proposed by their leader, Dahau.At the same time, elements within Gallian Army Command move to erase the Nameless in order to protect their own interests.John went to the hallway.Where is Mary? GENbathroom<|endoftext|>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different input_ids for .forward() and .generate()\n",
    "tokenizer.batch_decode([c[m] for c, m in zip(collated['input_ids'], collated['attention_mask'])][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Troops are divided into five classes : Scouts, Shocktroopers, Engineers, Lancers and Armored Soldier.Troopers can switch classes by changing their assigned weapon.Changing class does not greatly affect the stats gained while in a previous class.With victory in battle, experience points are awarded to the squad, which are distributed into five different attributes shared by the entire squad, a feature differing from early games\\'method of distributing to different unit types. = = Plot = = The game takes place during the Second Europan War.Gallian Army Squad 422, also known as \" The Nameless \", are a penal military unit composed of criminals, foreign deserters, and military offenders whose real names are erased from the records and thereon officially referred to by numbers.Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do, they are nevertheless up to the task, exemplified by their motto, Altaha Abilia, meaning \" Always Ready. \"The three main characters are No.7 Kurt Irving, an army officer falsely accused of treason who wishes to redeem himself ; Ace No.1 Imca, a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and No.13 Riela Marcellis, a seemingly jinxed young woman who is unknowingly a descendant of the Valkyria.Together with their fellow squad members, these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven, consisting of mostly Darcsen soldiers.Mary moved to the bathroom. As the Nameless officially do not exist, the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose face in the war.While at times this works to their advantage, such as a successful incursion into Imperial territory, other orders cause certain members of the 422nd great distress.One such member, Gusurg, becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven, attached to the ideal of Darcsen independence proposed by their leader, Dahau.At the same time, elements within Gallian Army Command move to erase the Nameless in order to protect their own interests.John went to the hallway.Where is Mary? GEN']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([c[m] for c, m in zip(collated['input_ids_generate'], collated['attention_mask_generate'])][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'labels', 'input_ids_generate', 'labels_mask', 'attention_mask', 'attention_mask_generate', 'target_text'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(batch_size=2, dataset=dataset_train, collate_fn=collate_fn)\n",
    "gen = iter(dl)\n",
    "batch = next(gen)\n",
    "batch.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
