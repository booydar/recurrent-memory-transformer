{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datasets\n",
    "from transformers import AutoTokenizer\n",
    "sys.path.append(\"..\")\n",
    "from babilong_utils import TaskDataset, SentenceSampler, NoiseInjectionDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### extract dataset archive\n",
    "# !unzip ../data/tasks_1-20_v1-2.zip -d ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa10_indefinite-knowledge_test.txt   qa1_single-supporting-fact_test.txt\n",
      "qa10_indefinite-knowledge_train.txt  qa1_single-supporting-fact_train.txt\n",
      "qa11_basic-coreference_test.txt      qa20_agents-motivations_test.txt\n",
      "qa11_basic-coreference_train.txt     qa20_agents-motivations_train.txt\n",
      "qa12_conjunction_test.txt\t     qa2_two-supporting-facts_test.txt\n",
      "qa12_conjunction_train.txt\t     qa2_two-supporting-facts_train.txt\n",
      "qa13_compound-coreference_test.txt   qa3_three-supporting-facts_test.txt\n",
      "qa13_compound-coreference_train.txt  qa3_three-supporting-facts_train.txt\n",
      "qa14_time-reasoning_test.txt\t     qa4_two-arg-relations_test.txt\n",
      "qa14_time-reasoning_train.txt\t     qa4_two-arg-relations_train.txt\n",
      "qa15_basic-deduction_test.txt\t     qa5_three-arg-relations_test.txt\n",
      "qa15_basic-deduction_train.txt\t     qa5_three-arg-relations_train.txt\n",
      "qa16_basic-induction_test.txt\t     qa6_yes-no-questions_test.txt\n",
      "qa16_basic-induction_train.txt\t     qa6_yes-no-questions_train.txt\n",
      "qa17_positional-reasoning_test.txt   qa7_counting_test.txt\n",
      "qa17_positional-reasoning_train.txt  qa7_counting_train.txt\n",
      "qa18_size-reasoning_test.txt\t     qa8_lists-sets_test.txt\n",
      "qa18_size-reasoning_train.txt\t     qa8_lists-sets_train.txt\n",
      "qa19_path-finding_test.txt\t     qa9_simple-negation_test.txt\n",
      "qa19_path-finding_train.txt\t     qa9_simple-negation_train.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/tasks_1-20_v1-2/en-10k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"qa2_two-supporting-facts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griver/anaconda3/envs/rmt/lib/python3.9/site-packages/datasets/load.py:1429: FutureWarning: The repository for pg19 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/pg19\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_path =f\"../data/tasks_1-20_v1-2/en-10k/{task}_train.txt\"\n",
    "test_path = f\"../data/tasks_1-20_v1-2/en-10k/{task}_test.txt\"\n",
    "noise_dataset_name = \"pg19\"\n",
    "noise_dataset = datasets.load_dataset(noise_dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load task datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task \n",
    "task_dataset_train = TaskDataset(train_path)\n",
    "task_dataset_test = TaskDataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background text\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "noise_sampler_train = SentenceSampler(noise_dataset['train'], tokenizer=tokenizer)\n",
    "noise_sampler_test = SentenceSampler(noise_dataset['test'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500               # max number of tokens in sample\n",
    "dataset_train = NoiseInjectionDataset(task_dataset=task_dataset_train,\n",
    "                                        noise_sampler=noise_sampler_train,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        sample_size=sample_size)\n",
    "\n",
    "dataset_test = NoiseInjectionDataset(task_dataset=task_dataset_test,\n",
    "                                        noise_sampler=noise_sampler_test,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        sample_size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['facts', 'question', 'answer', 'references', 'background_text', 'fact_positions', 'input_tokens', 'question_tokens', 'target_tokens'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset_train[0]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary moved to the bathroom.\n",
      "Sandra journeyed to the bedroom.\n",
      "Mary got the football there.\n",
      "John went to the kitchen.\n",
      "Mary went back to the kitchen.\n",
      "Mary went back to the garden.\n",
      "fact position: [ 1  7  7 11 13 15]\n",
      "question: Where is the football? \n",
      "\n",
      "BACKGROUND:\n",
      "'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Old Testament of the King James Version of the Bible\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.',\n",
      "'1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep.',\n",
      "'And the Spirit of God moved upon the face of the\n",
      "waters.',\n",
      "'1:3 And God said, Let there be light: and there was light.',\n",
      "'1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.',\n",
      "'1:5 And God called the light Day, and the darkness he called Night.',\n",
      "'And the evening and the morning were the first day.',\n",
      "'1:6 And God said, Let there be a firmament in the midst of the waters,\n",
      "and let it divide the waters from the waters.',\n",
      "'1:7 And God made the firmament, and divided the waters which were\n",
      "under the firmament from the waters which were above the firmament:\n",
      "and it was so.',\n",
      "'1:8 And God called the firmament Heaven.',\n",
      "'And the evening and the\n",
      "morning were the second day.',\n",
      "'1:9 And God said, Let the waters under the heaven be gathered together\n",
      "unto one place, and let the dry land appear: and it was so.',\n",
      "'1:10 And God called the dry land Earth; and the gathering together of\n",
      "the waters called he Seas: and God saw that it was good.',\n",
      "'1:11 And God said, Let the earth bring forth grass, the herb yielding\n",
      "seed, and the fruit tree yielding fruit after his kind, whose seed is\n",
      "in itself, upon the earth: and it was so.',\n",
      "'1:12 And the earth brought forth grass, and herb yielding seed after\n",
      "his kind, and the tree yielding fruit, whose seed was in itself, after\n",
      "his kind: and God saw that it was good.',\n",
      "'1:13 And the evening and the morning were the third day.',\n",
      "'1:14 And God said, Let there be lights in the firmament of the heaven\n",
      "to divide the day from the night; and let them be for signs, and for\n",
      "seasons, and for days, and years',\n"
     ]
    }
   ],
   "source": [
    "for f in sample['facts']:\n",
    "    print(f)\n",
    "print(\"fact position:\", sample['fact_positions'])\n",
    "print(\"question:\", sample['question'])\n",
    "print(\"\\nBACKGROUND:\")\n",
    "\n",
    "background_text = tokenizer.batch_decode(sample['background_text'])\n",
    "for s in background_text[:20]:\n",
    "    print(f'\\'{s}\\',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts: Mary moved to the bathroom. Sandra journeyed to the bedroom. Mary got the football there. John went to the kitchen. Mary went back to the kitchen. Mary went back to the garden.\n",
      "Question: Where is the football? \n",
      "Answer: garden\n",
      "References: Mary got the football there. Mary went back to the garden.\n",
      "\n",
      "Background text:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Old Testament of the King James Version of the Bible\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth. 1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep. And the Spirit of God moved upon the face of the\n",
      "waters. 1:3 And God said, Let there be light: and there was light. 1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness. 1:5 And God called the light Day, and the darkness he called Night. And the evening and the morning were the first day. 1:6 And God said, Let there be a firmament in the midst of the waters,\n",
      "and let it divide the waters from the waters. 1:7 And God made the firmament, and divided the waters which were\n",
      "under the firmament from the waters which were above the firmament:\n",
      "and it was so. 1:8 And God called the firmament Heaven. And the evening and the\n",
      "morning were the second day. 1:9 And God said, Let the waters under the heaven be gathered together\n",
      "unto one place, and let the dry land appear: and it was so. 1:10 And God called the dry land Earth; and the gathering together of\n",
      "the waters called he Seas: and God saw that it was good. 1:11 And God said, Let the earth bring forth grass, the herb yielding\n",
      "seed, and the fruit tree yielding fruit after his kind, whose seed is\n",
      "in itself, upon the earth: and it was so. 1:12 And the earth brought forth grass, and herb yielding seed after\n",
      "his kind, and the tree yielding fruit, whose seed was in itself, after\n",
      "his kind: and God saw that it was good. 1:13 And the evening and the morning were the third day. 1:14 And God said, Let there be lights in the firmament of the heaven\n",
      "to divide the day from the night; and let them be for signs, and for\n",
      "seasons, and for days, and years\n",
      "Fact positions:  [ 1  7  7 11 13 15]\n",
      "Combined input:  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Old Testament of the King James Version of the Bible\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.Mary moved to the bathroom.1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep.And the Spirit of God moved upon the face of the\n",
      "waters.1:3 And God said, Let there be light: and there was light.1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.1:5 And God called the light Day, and the darkness he called Night.And the evening and the morning were the first day.Sandra journeyed to the bedroom.Mary got the football there.1:6 And God said, Let there be a firmament in the midst of the waters,\n",
      "and let it divide the waters from the waters.1:7 And God made the firmament, and divided the waters which were\n",
      "under the firmament from the waters which were above the firmament:\n",
      "and it was so.1:8 And God called the firmament Heaven.And the evening and the\n",
      "morning were the second day.John went to the kitchen.1:9 And God said, Let the waters under the heaven be gathered together\n",
      "unto one place, and let the dry land appear: and it was so.1:10 And God called the dry land Earth; and the gathering together of\n",
      "the waters called he Seas: and God saw that it was good.Mary went back to the kitchen.1:11 And God said, Let the earth bring forth grass, the herb yielding\n",
      "seed, and the fruit tree yielding fruit after his kind, whose seed is\n",
      "in itself, upon the earth: and it was so.1:12 And the earth brought forth grass, and herb yielding seed after\n",
      "his kind, and the tree yielding fruit, whose seed was in itself, after\n",
      "his kind: and God saw that it was good.Mary went back to the garden.1:13 And the evening and the morning were the third day.1:14 And God said, Let there be lights in the firmament of the heaven\n",
      "to divide the day from the night; and let them be for signs, and for\n",
      "seasons, and for days, and years\n",
      "Target: garden\n"
     ]
    }
   ],
   "source": [
    "\n",
    "facts = sample['facts']\n",
    "question = sample['question']\n",
    "answer = tokenizer.decode(sample['target_tokens'])\n",
    "\n",
    "#background_text = sample['background_text']\n",
    "\n",
    "input_tokens = tokenizer.decode(sample['input_tokens'])\n",
    "\n",
    "print(f\"Facts: {' '.join(facts)}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"References: {' '.join(sample['references'])}\")\n",
    "print()\n",
    "print('Background text: ', ' '.join(background_text))\n",
    "print('Fact positions: ', sample['fact_positions'])\n",
    "print('Combined input: ', input_tokens)\n",
    "\n",
    "print(f\"Target: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "gen_token = tokenizer.encode('GEN')[0]\n",
    "eos_token = tokenizer.eos_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    targets = [torch.tensor(b['target_tokens']) for b in batch]\n",
    "    input_ids = [torch.tensor(b['input_tokens'] + [gen_token] + b['target_tokens'] + [eos_token]) for b in batch]\n",
    "    gen_inputs = [torch.tensor(b['input_tokens'] + [gen_token]) for b in batch]\n",
    "\n",
    "    attention_mask = [torch.ones_like(b, dtype=int) for b in input_ids]\n",
    "    labels_mask = [torch.zeros_like(b, dtype=bool) for b in input_ids]\n",
    "    for m, t in zip(labels_mask, targets):\n",
    "        m[-len(t) - 2:] = True\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value, batch_first=True)\n",
    "    gen_inputs = pad_sequence(gen_inputs, padding_value=id_pad_value, batch_first=True)\n",
    "    # labels = pad_sequence(input_ids, padding_value=-100, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0, batch_first=True)\n",
    "    labels_mask = pad_sequence(labels_mask, padding_value=0, batch_first=True)\n",
    "\n",
    "    collated = {}\n",
    "    collated['input_ids'] = collated['labels'] = input_ids\n",
    "    collated['input_ids_generate'] = gen_inputs\n",
    "    collated['labels_mask'] = labels_mask\n",
    "    collated['attention_mask'] = attention_mask.bool()\n",
    "    collated['attention_mask_generate'] = (gen_inputs != id_pad_value).bool()\n",
    "\n",
    "    collated['target_text'] = [b['answer'] for b in batch]\n",
    "    \n",
    "    collated['background_text'] = [b['background_text'] for b in batch]\n",
    "    collated['facts'] = [b['facts'] for b in batch]\n",
    "    collated['question'] = [b['question'] for b in batch]\n",
    "    \n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'labels', 'input_ids_generate', 'labels_mask', 'attention_mask', 'attention_mask_generate', 'target_text', 'background_text', 'facts', 'question'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [dataset_train[i] for i in range(10)]\n",
    "collated = collate_fn(batch)\n",
    "collated.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels are marked with labels_mask\n",
    "#tokenizer.batch_decode([c[m] for c, m in zip(collated['input_ids'], collated['labels_mask'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different input_ids for .forward() and .generate()\n",
    "#tokenizer.batch_decode([c[m] for c, m in zip(collated['input_ids'], collated['attention_mask'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.batch_decode([c[m] for c, m in zip(collated['input_ids_generate'], collated['attention_mask_generate'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if Contriever can find relevant facts from the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "contriever_path = \"../../contriever/\" \n",
    "if contriever_path not in sys.path:\n",
    "    sys.path.append(contriever_path)\n",
    "\n",
    "#for p in sys.path:    \n",
    "#    print(p)\n",
    "\n",
    "from src.contriever import Contriever\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/contriever were not used when initializing Contriever: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "contriever = Contriever.from_pretrained(\"facebook/contriever\") \n",
    "c_tokenizer = AutoTokenizer.from_pretrained(\"facebook/contriever\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def compite_statistics(res, num_retr=5, verbose=False):\n",
    "    N = len(res['query'])\n",
    "    num_retrieved_facts = 0\n",
    "    num_facts = 0\n",
    "    num_retrieves = 0\n",
    "    for i in range(N):\n",
    "        scores = torch.inner(res['query'][i], res['sentences'][i])\n",
    "        sorted_scores = torch.argsort(scores)\n",
    "        \n",
    "        fact_ids = res['facts_ids'][i]\n",
    "        k = num_retr if num_retr > 0 else len(fact_ids) \n",
    "        top_k = sorted_scores[-k:]\n",
    "        \n",
    "        num_retrieved_facts += sum(id < len(fact_ids) for id in top_k)\n",
    "        num_facts += len(fact_ids)\n",
    "        num_retrieves += k\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"retrieved sentences: {top_k}, all_facts: {fact_ids}\")    \n",
    "\n",
    "    stats = dict()\n",
    "    stats['precision'] = num_retrieved_facts/ num_retrieves\n",
    "    stats['recall'] = num_retrieved_facts / num_facts\n",
    "    \n",
    "    print(f\"precision: {stats['precision']:.2f}, recall: {stats['recall']:.2f}\")\n",
    "    return stats\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_contriever_embeds(collated):\n",
    "    sent_embeds = []\n",
    "    facts_ids = []\n",
    "    query_embeds = []\n",
    "    N = len(collated['facts'])\n",
    "    for i in range(N):\n",
    "        sentences = []\n",
    "        sentences.extend(collated['facts'][i])\n",
    "        facts_ids.append(np.arange(len(sentences)))\n",
    "        background_text = tokenizer.batch_decode(collated['background_text'][i])\n",
    "        sentences.extend(background_text)\n",
    "        sentences.append(collated['question'][i]) # append as this is a single str\n",
    "        \n",
    "        # print(\"fact_ids:\", facts_ids[i])\n",
    "        # for i, s in enumerate(sentences):\n",
    "        #     print(f\"{i}: type={type(s).__name__}, {s}\")\n",
    "            \n",
    "        inputs = c_tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        embeds = contriever(**inputs)\n",
    "        sent_embeds.append(embeds[:-1])\n",
    "        query_embeds.append(embeds[-1])\n",
    "        \n",
    "        #print('===================')\n",
    "    #print(\"DONE\")\n",
    "    return dict(query=query_embeds, sentences=sent_embeds, facts_ids=facts_ids) \n",
    "\n",
    "#type(collated[\"question\"][0])\n",
    "res = get_contriever_embeds(collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 1.00, recall: 0.07\n",
      "precision: 0.84, recall: 0.28\n",
      "precision: 0.78, recall: 0.53\n"
     ]
    }
   ],
   "source": [
    "#sum([s.shape[0] for s in res['sentences']])\n",
    "stats = compite_statistics(res, num_retr=1)\n",
    "stats = compite_statistics(res, num_retr=5)\n",
    "stats = compite_statistics(res, num_retr=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Contriever Similiarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;2;191;128;191mWhat a nice red background!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def monocolor(v, text):\n",
    "    r=127 + int(v*128) \n",
    "    b=127 + int(128*(1-v))\n",
    "    g=128\n",
    "    #print(f\"{r},{g},{b}\")\n",
    "    return colored_background(r, g, b, text)\n",
    "    \n",
    "def colored_background(r, g, b, text):\n",
    "    return f'\\033[48;2;{r};{g};{b}m{text}\\033[0m'\n",
    "\n",
    "text = \"What a nice red background!\"\n",
    "colored_text = colored_background(255, 0, 0, text)\n",
    "colored_text = monocolor(0.5, text)\n",
    "print(colored_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contriever-based similarity score between question and Babilong context\n",
      "---------------------------------\n",
      "QUESTION: Where is the football? \n",
      "---------------------------------\n",
      "TOP 24 sentences sorted from highest to lowest similarity score:\n",
      "0.961, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;127;128;255m#2. Mary got the football there.\u001b[0m\n",
      "0.682, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;190;128;191m#10. Mary dropped the football.\u001b[0m\n",
      "0.586, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;211;128;170m#23. 2:9 And out of the ground made the LORD\u001b[0m\n",
      "0.578, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;213;128;168m#11. John got the milk there.\u001b[0m\n",
      "0.572, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;214;128;167m#4. Mary went back to the kitchen.\u001b[0m\n",
      "0.562, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;217;128;164m#6. Sandra went back to the office.\u001b[0m\n",
      "0.561, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;217;128;164m#0. Mary moved to the bathroom.\u001b[0m\n",
      "0.555, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;218;128;163m#5. Mary went back to the garden.\u001b[0m\n",
      "0.552, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;219;128;162m#13. 1:30 And to every beast of the earth, and to every fowl of the air, and to every thing that creepeth upon the earth...\u001b[0m\n",
      "0.551, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;219;128;162m#12. 1:29 And God said, Behold, I have given you every herb bearing seed, which is upon the face of all the earth, and e...\u001b[0m\n",
      "0.549, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;220;128;161m#22. 2:8 And the LORD God planted a garden eastward in Eden; and there he put the man whom he had formed.\u001b[0m\n",
      "0.547, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;220;128;161m#3. John went to the kitchen.\u001b[0m\n",
      "0.544, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;221;128;160m#9. Daniel went back to the kitchen.\u001b[0m\n",
      "0.541, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;222;128;159m#8. Sandra journeyed to the hallway.\u001b[0m\n",
      "0.540, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;222;128;159m#19. 2:4 These are the generations of the heavens and of the earth when they were created, in the day that the LORD God ...\u001b[0m\n",
      "0.531, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;224;128;157m#17. 2:2 And on the seventh day God ended his work which he had made; and he rested on the seventh day from all his work...\u001b[0m\n",
      "0.516, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;227;128;154m#14. 1:31 And God saw every thing that he had made, and, behold, it was very good.\u001b[0m\n",
      "0.512, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;228;128;153m#1. Sandra journeyed to the bedroom.\u001b[0m\n",
      "0.511, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;228;128;153m#20. 2:6 But there went up a mist from the earth, and watered the whole face of the ground.\u001b[0m\n",
      "0.510, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;229;128;152m#21. 2:7 And the LORD God formed man of the dust of the ground, and breathed into his nostrils the breath of life; and m...\u001b[0m\n",
      "0.509, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;229;128;152m#18. 2:3 And God blessed the seventh day, and sanctified it: because that in it he had rested from all his work which Go...\u001b[0m\n",
      "0.493, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;232;128;149m#16. 2:1 Thus the heavens and the earth were finished, and all the host of them.\u001b[0m\n",
      "0.441, \u001b[48;2;150;255;150m[F]\u001b[0m: \u001b[48;2;244;128;137m#7. John moved to the office.\u001b[0m\n",
      "0.395, \u001b[48;2;200;200;200m[N]\u001b[0m: \u001b[48;2;255;128;127m#15. And the evening and the morning were the sixth day.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def print_sorted_sentences_scores(collated, idx):\n",
    "    sentences = []\n",
    "    sentences.extend(collated['facts'][idx])\n",
    "    facts_ids = np.arange(len(sentences))\n",
    "    background_text = tokenizer.batch_decode(collated['background_text'][idx])\n",
    "    sentences.extend(background_text)\n",
    "    sentences.append(collated['question'][idx]) # append as this is a single str\n",
    "    \n",
    "    inputs = c_tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    embeds = contriever(**inputs)\n",
    "    sent_embeds = embeds[:-1]\n",
    "    query_embeds = embeds[-1]\n",
    "    \n",
    "    scores = torch.inner(query_embeds, sent_embeds)        \n",
    "    print(\"Contriever-based similarity score between question and Babilong context\")\n",
    "    #print(scores)\n",
    "    \n",
    "    normalized_scores = (scores-scores.min())/(scores.max()-scores.min())\n",
    "    #normalized_scores = normalized_scores.tolist()\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"QUESTION:\", sentences[-1])\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"TOP {min(len(sentences)-1, 25)} sentences sorted from highest to lowest similarity score:\")\n",
    "    for i in reversed(torch.argsort(normalized_scores)[-25:].tolist()):\n",
    "        norm_score = normalized_scores[i]\n",
    "        texttype = colored_background(150, 255, 150, \"[F]\") if i in facts_ids else colored_background(200, 200, 200, \"[N]\")\n",
    "        sent = f\"#{i}. \" + sentences[i].replace(\"\\n\", \" \")\n",
    "        if len(sent) > 120:\n",
    "            sent = sent[:120] + \"...\"\n",
    "        print(f\"{scores[i]:.3f}, {texttype:>8s}: {monocolor(1-norm_score, sent)}\")\n",
    "\n",
    "\n",
    "print_sorted_sentences_scores(collated, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create environment for multi-step retrieval from a history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval_env import QARetrievalEnv, RNDStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = QARetrievalEnv(collated, contriever, c_tokenizer, tokenizer, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['acts_embed', 'acts_text', 'acts_mask', 'state_embed'])\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "print(s.keys())\n",
    "print(s['acts_embed'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== step #0 ===\n",
      "0 Mary moved to the bathroom.\n",
      "1 Sandra journeyed to the bedroom.\n",
      "2 Mary got the football there.\n",
      "3 John went to the kitchen.\n",
      "4 Mary went back to the kitchen.\n",
      "\n",
      "action mask: [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== step #0 ===\")\n",
    "for i, sent in enumerate(s['acts_text'][0:5]):\n",
    "    print(i, sent)\n",
    "print(\"\\naction mask:\", s['acts_mask'])\n",
    "acts = s['acts_mask'].nonzero()[0]\n",
    "env.step(acts[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'labels', 'input_ids_generate', 'labels_mask', 'attention_mask', 'attention_mask_generate', 'target_text'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(batch_size=2, dataset=dataset_train, collate_fn=collate_fn)\n",
    "gen = iter(dl)\n",
    "batch = next(gen)\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contriever'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Contriever\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'contriever'"
     ]
    }
   ],
   "source": [
    "from contriever import Contriever\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
